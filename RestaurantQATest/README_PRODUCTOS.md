# üß™ Suite de Pruebas Automatizadas - RestaurantQA

## üìã Descripci√≥n

Suite completa de pruebas automatizadas para la aplicaci√≥n **RestaurantQA**, implementada con **Python**, **Selenium WebDriver** y **pytest**. Las pruebas est√°n basadas en el dise√±o de **particiones equivalentes** y siguen el patr√≥n **Page Object Model (POM)** para maximizar la mantenibilidad y reutilizaci√≥n del c√≥digo.

---

## üèóÔ∏è Estructura del Proyecto

```
RestaurantQATest/
‚îÇ
‚îú‚îÄ‚îÄ üìÅ Data/                          # Datos de prueba en CSV
‚îÇ   ‚îú‚îÄ‚îÄ productos_tests.csv          # 33 casos de prueba para productos
‚îÇ   ‚îî‚îÄ‚îÄ clientes_tests.csv           # 36 casos de prueba para clientes
‚îÇ
‚îú‚îÄ‚îÄ üìÅ pages/                         # Page Object Model (POM)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ base_page.py                 # Clase base con m√©todos comunes
‚îÇ   ‚îî‚îÄ‚îÄ producto_page.py             # Page Object para productos
‚îÇ
‚îú‚îÄ‚îÄ üìÅ tests/                         # Suite de pruebas
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ test_productos.py            # Tests automatizados de productos
‚îÇ
‚îú‚îÄ‚îÄ üìÅ reports/                       # Reportes generados (auto-creado)
‚îÇ   ‚îú‚îÄ‚îÄ report.html                  # Reporte HTML de pytest
‚îÇ   ‚îî‚îÄ‚îÄ pytest.log                   # Logs de ejecuci√≥n
‚îÇ
‚îú‚îÄ‚îÄ üìÑ conftest.py                    # Configuraci√≥n de fixtures de pytest
‚îú‚îÄ‚îÄ üìÑ pytest.ini                     # Configuraci√≥n de pytest
‚îú‚îÄ‚îÄ üìÑ requirements.txt               # Dependencias del proyecto
‚îî‚îÄ‚îÄ üìÑ README.md                      # Esta documentaci√≥n
```

---

## üéØ M√≥dulos de Prueba

### ‚úÖ M√≥dulo: Productos

**Archivo de pruebas:** `tests/test_productos.py`  
**Datos de prueba:** `Data/productos_tests.csv`  
**Page Object:** `pages/producto_page.py`

#### Casos de Prueba: 33 Total

**Particiones V√°lidas (2 casos):**
- ‚úÖ **PR1**: Valores m√≠nimos permitidos (Precio: 0.01, Stock: 0)
- ‚úÖ **PR2**: Valores m√°ximos permitidos (Precio: 1000, Stock: 150, Descripci√≥n: 100 chars)

**Particiones Inv√°lidas (31 casos):**
- ‚ùå **PR3-PR33**: Diversos casos que incluyen:
  - Nombre vac√≠o
  - Nombre excede 20 caracteres
  - Nombre con caracteres especiales (@, n√∫meros)
  - Precio = 0 o fuera del rango (0.01 - 1000)
  - Stock negativo o > 150
  - Descripci√≥n < 5 caracteres o > 100 caracteres

#### Validaciones Cubiertas:
- **Nombre**: Required, Length(4-20 caracteres)
- **Precio**: Range(0.01 - 1000)
- **Stock**: Range(0 - 150)
- **Descripci√≥n**: Required, Length(5-100 caracteres)
- **Categor√≠a ID**: Required, > 0

---

## üöÄ Instalaci√≥n y Configuraci√≥n

### 1Ô∏è‚É£ Pre-requisitos

- **Python 3.8+** instalado
- **Google Chrome** instalado
- **Aplicaci√≥n RestaurantQA** corriendo en `http://localhost:5020`

### 2Ô∏è‚É£ Instalaci√≥n de Dependencias

```bash
# Navegar al directorio del proyecto
cd RestaurantQATest

# Crear entorno virtual (opcional pero recomendado)
python -m venv venv

# Activar entorno virtual
# En Linux/Mac:
source venv/bin/activate
# En Windows:
venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

### 3Ô∏è‚É£ Verificar Instalaci√≥n

```bash
# Verificar que pytest est√° instalado
pytest --version

# Verificar que selenium est√° instalado
python -c "import selenium; print(selenium.__version__)"
```

---

## ‚ñ∂Ô∏è Ejecuci√≥n de Pruebas

### Ejecutar TODOS los tests

```bash
pytest
```

### Ejecutar tests de un m√≥dulo espec√≠fico

```bash
# Solo tests de productos
pytest -m productos

# Solo tests de clientes
pytest -m clientes
```

### Ejecutar tests de smoke (cr√≠ticos)

```bash
pytest -m smoke
```

### Ejecutar un archivo espec√≠fico

```bash
pytest tests/test_productos.py
```

### Ejecutar con reporte HTML

```bash
pytest --html=reports/report.html --self-contained-html
```

### Ejecutar en modo verbose (m√°s detalles)

```bash
pytest -v
```

### Ejecutar tests en paralelo (m√°s r√°pido)

```bash
pytest -n auto
```

### Ejecutar con output detallado

```bash
pytest -vv -s
```

---

## üìä Interpretaci√≥n de Resultados

### Ejemplo de Salida Exitosa

```
tests/test_productos.py::test_registro_producto[PR1] ‚úÖ PASSED
tests/test_productos.py::test_registro_producto[PR2] ‚úÖ PASSED
tests/test_productos.py::test_registro_producto[PR3] ‚úÖ PASSED

==================== 33 passed in 45.23s ====================
```

### Ejemplo de Salida con Fallo

```
tests/test_productos.py::test_registro_producto[PR5] ‚ùå FAILED

FAILURES
________________________ test_registro_producto[PR5] ________________________

    ‚ùå Caso PR5 FALL√ì: Se esperaba que el producto fuera ACEPTADO pero fue RECHAZADO.
       Datos: Nombre='Hamburguesa', Precio=25.5, Stock=50, Descripci√≥n='Rico'
       Partici√≥n: V√°lida - Valores intermedios
       Errores de validaci√≥n: {'descripcion': 'La descripcion del producto no puede pasar de los 20 caracteres y no ser menos a 4.'}
```

---

## üìà Reportes

### Reporte HTML

Despu√©s de ejecutar las pruebas, se genera un reporte HTML interactivo en:

```
reports/report.html
```

Abrir con navegador para ver:
- ‚úÖ Tests pasados
- ‚ùå Tests fallidos
- ‚ö†Ô∏è Tests con warnings
- üìä Gr√°ficos y estad√≠sticas
- üïê Tiempo de ejecuci√≥n

### Logs Detallados

Los logs de ejecuci√≥n se guardan en:

```
reports/pytest.log
```

---

## üõ†Ô∏è Mantenimiento de Tests

### Agregar Nuevos Casos de Prueba

1. **Editar el CSV de datos:**
   - Abrir `Data/productos_tests.csv`
   - Agregar una nueva fila con los datos del caso

2. **No se requiere modificar c√≥digo:**
   - Las pruebas son parametrizadas
   - Autom√°ticamente tomar√°n los nuevos casos

### Modificar Validaciones

Si cambian las validaciones del backend:

1. **Actualizar el Page Object:**
   - Editar `pages/producto_page.py`
   - Modificar localizadores si cambi√≥ el HTML

2. **Actualizar casos de prueba:**
   - Editar `Data/productos_tests.csv`
   - Ajustar valores esperados seg√∫n nuevas validaciones

---

## üèÜ Mejores Pr√°cticas Implementadas

### ‚úÖ Page Object Model (POM)

- **Separaci√≥n de responsabilidades:** L√≥gica de p√°gina vs. l√≥gica de prueba
- **Reutilizaci√≥n:** M√©todos comunes en `BasePage`
- **Mantenibilidad:** Cambios en UI solo afectan Page Objects

### ‚úÖ Data-Driven Testing

- **CSV como fuente de datos:** F√°cil de editar por no-programadores
- **Pruebas parametrizadas:** Un test, m√∫ltiples casos
- **Cobertura completa:** Todas las particiones equivalentes

### ‚úÖ Asserts Claros

```python
assert producto_page.is_producto_registered(), \
    f"‚ùå Caso {case['caso']} FALL√ì: Se esperaba ACEPTADO pero fue RECHAZADO.\n" \
    f"   Datos: Nombre='{nombre}', Precio={precio}..."
```

### ‚úÖ Configuraci√≥n Centralizada

- **conftest.py:** Fixtures compartidas
- **pytest.ini:** Configuraci√≥n de pytest
- **requirements.txt:** Dependencias versionadas

### ‚úÖ Marcadores de Tests

```python
@pytest.mark.productos  # Filtrar por m√≥dulo
@pytest.mark.smoke      # Tests cr√≠ticos
@pytest.mark.regression # Suite completa
```

---

## üêõ Troubleshooting

### Error: `ModuleNotFoundError: No module named 'selenium'`

**Soluci√≥n:**
```bash
pip install -r requirements.txt
```

### Error: `WebDriverException: Chrome not reachable`

**Soluci√≥n:**
- Verificar que Google Chrome est√° instalado
- Actualizar webdriver: `pip install --upgrade webdriver-manager`

### Error: `Connection refused (localhost:5020)`

**Soluci√≥n:**
- Verificar que la aplicaci√≥n RestaurantQA est√° corriendo
- Comprobar el puerto en `conftest.py` fixture `base_url`

### Tests muy lentos

**Soluci√≥n:**
```bash
# Ejecutar en paralelo
pytest -n auto
```

### No se generan reportes

**Soluci√≥n:**
```bash
# Crear directorio de reportes
mkdir -p reports

# Ejecutar con reporte expl√≠cito
pytest --html=reports/report.html --self-contained-html
```

---

## üìö Recursos Adicionales

### Documentaci√≥n Oficial

- **Selenium:** https://selenium-python.readthedocs.io/
- **Pytest:** https://docs.pytest.org/
- **Page Object Pattern:** https://selenium-python.readthedocs.io/page-objects.html

### Comandos √ötiles

```bash
# Ver todos los marcadores disponibles
pytest --markers

# Ver fixtures disponibles
pytest --fixtures

# Ejecutar solo tests que fallaron la √∫ltima vez
pytest --lf

# Detener al primer fallo
pytest -x

# Mostrar 10 tests m√°s lentos
pytest --durations=10
```

---

## üë• Contribuciones

### Agregar un Nuevo M√≥dulo de Pruebas

1. **Crear Page Object:**
   ```python
   # pages/nuevo_modulo_page.py
   from pages.base_page import BasePage
   
   class NuevoModuloPage(BasePage):
       # Definir localizadores y m√©todos
   ```

2. **Crear archivo de tests:**
   ```python
   # tests/test_nuevo_modulo.py
   import pytest
   from pages.nuevo_modulo_page import NuevoModuloPage
   
   @pytest.mark.nuevo_modulo
   def test_caso_1(driver, base_url):
       # Implementar test
   ```

3. **Agregar marcador en pytest.ini:**
   ```ini
   markers =
       nuevo_modulo: Tests del nuevo m√≥dulo
   ```

---

## üìù Notas Importantes

### ‚ö†Ô∏è Consideraciones

1. **Base de datos:** Las pruebas insertar√°n datos reales en la BD
   - Usar BD de pruebas, no producci√≥n
   - Considerar limpiar datos despu√©s de cada ejecuci√≥n

2. **Headless mode:** Por defecto, Chrome corre en modo headless
   - Para ver el navegador, editar `conftest.py`
   - Comentar l√≠nea: `opts.add_argument("--headless=new")`

3. **Timeouts:** Ajustar seg√∫n velocidad de la m√°quina
   - Editar `driver.implicitly_wait(5)` en `conftest.py`

---

## üìû Soporte

Para problemas o preguntas:
- Revisar secci√≥n de **Troubleshooting**
- Consultar logs en `reports/pytest.log`
- Verificar que la aplicaci√≥n est√© corriendo

---

## üéì Conceptos de Testing Aplicados

### Particiones Equivalentes

Dividir el dominio de entrada en clases donde se espera que el sistema se comporte de manera similar:

- **Partici√≥n V√°lida:** Datos que el sistema debe aceptar
- **Partici√≥n Inv√°lida:** Datos que el sistema debe rechazar

### Valores L√≠mite (Boundary Values)

Probar en los bordes de las particiones:

- **PR1:** Valores m√≠nimos (0.01, 0, 5 chars)
- **PR2:** Valores m√°ximos (1000, 150, 100 chars)

### Cobertura de Casos

- **2 casos v√°lidos** (particiones aceptables)
- **31 casos inv√°lidos** (particiones rechazables)
- **Cobertura total:** 100% de particiones identificadas

---

## ‚ú® Caracter√≠sticas Destacadas

‚úÖ **Arquitectura POM** - C√≥digo mantenible y escalable  
‚úÖ **Data-Driven Testing** - Casos de prueba en CSV  
‚úÖ **Pruebas Parametrizadas** - DRY (Don't Repeat Yourself)  
‚úÖ **Reportes HTML** - Visualizaci√≥n clara de resultados  
‚úÖ **Logs Detallados** - Debugging facilitado  
‚úÖ **Marcadores Personalizados** - Ejecuci√≥n selectiva  
‚úÖ **Fixtures Reutilizables** - Setup/Teardown autom√°tico  
‚úÖ **Asserts Descriptivos** - Mensajes de error claros  

---

**Versi√≥n:** 1.0.0  
**√öltima actualizaci√≥n:** Octubre 2025  
**Licencia:** MIT  
